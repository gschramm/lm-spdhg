% Latex template for submission to the 16th International Meeting on Fully 3D Image Reconstruction 
% in Radiology and Nuclear Medicine (Fully3D 2021)
%
% Author: G.Schramm
% Date:   Oct 2020
%
% In case you encouter problems, you can raise a github issue here:
% https://github.com/gschramm/fully3d_2021_templates/issues
%
% 
% To build this document, we recommend to use latexmk via:
% ```latexmk -pdf fully3d_template.tex```
% Building in the online editor overleaf also works.

\documentclass[11pt,twocolumn,twoside]{article}
\usepackage{fully3d}

%%%%%% add your extra packages here (if needed)                                       %%%%%
%%%%%% before, have a look which packages are already imported by the fully3d package %%%%%

\usepackage{amssymb}
\usepackage{algorithmicx}
\usepackage{algpseudocode}

% define float env for algorithm
\usepackage{float}
\floatstyle{ruled}
\newfloat{algorithm}{h}{loa}
\floatname{algorithm}{Algorithm}

%%%%% add your bibtex file that contains the bibtex entries here %%%%%
%%%%% please include DOIs in the bibtex entries if possible      %%%%%
\addbibresource{fully3d_2021.bib}

% custom definitions
\DeclareMathOperator{\proj}{proj}
\DeclareMathOperator{\prox}{prox}
\DeclareMathOperator*{\argmin}{arg\,min}

\begin{document}


%-------------------------------------------------------------------------------------------
%%%%% add your title here %%%%%
\title{Fast and memory-efficient reconstruction of sparse TOF PET data with non-smooth priors} 

%%%%% add authors and affiliations here %%%%%
\author[1]{Georg~Schramm}
\author[2]{Martin~Holler}

\affil[1]{Department of Imaging and Pathology, Division of Nuclear Medicine,
          KU Leven, Belgium}

\affil[2]{Institute for Mathematics and Scientific Computing, 
          University of Graz, Austria}

%%%%% don't change these 2 lines %%%%%
\maketitle
\thispagestyle{fancy}



%-------------------------------------------------------------------------------------------
%%%%% add your summary (abstract) here               %%%%%%
%%%%% use footnotesize for this section              %%%%%%
%%%%% please stick to the customabstract environment %%%%%% 


\begin{customabstract}
Foo bar.
\end{customabstract}


%-------------------------------------------------------------------------------------------
%%%%% main text %%%%%    
\section{Introduction}

Due to limitations in acquisition time, injectable dose and scanner sensitivity,
acquired data in positron emission tomography (PET) suffer from high levels of
Poisson noise that is transfered into the reconstructed image necessitating
noise suppression during or post reconstruction.
One possible way of noise suppression is the maximum a posteriori approach
where a smoothing prior added next to the data fidelity term (the negative
Poisson loglikelihood) in the cost function optimized in iterative image 
reconstruction.
Unfortunately, many advanced smoothing priors such as e.g. Total Variation (TV) [XXX],
Generalized TV [XXX], Directional TV [XXX] or Parallel Level Sets [XXX] are non-smooth 
functions which permits the use of simple and efficient purely gradient-based
optimization algortihms.
Moreover, due to the large number of data bins in a (time-of-flight) sinogram
of modern PET scanners, the compution time for a single evaluation of the complete
forward (and adjoint) model is usually slow favoring optimiztion algorithms that
use only a subset of the data ine every update step like maximum expectation maximization
with ordered subsets (OSEM).

Recently, Chambolle et al. \cite{Chambolle2018} and  Ehrhardt et al. \cite{Ehrhardt2019} introduced 
the stochastic primal dual hybrid gradient (SPDHG) algorithm which is a convergent algorithms
to allows to solve the PET reconstruction problem inlcuding many non-smooth priors with
only a few iterations. 
Algorithm \ref{alg:spdhg} shows SPDHG using a typical PET forward model.
As seen in line 6 and 7, in every update only a forward and backprojection of subset
of the data is required.
Using two clinical FDG and Fluorbetapir data sets from the Siemens mMR, 
it was shown in \cite{Ehrhardt2019}, that approximately 10 iterations, meaning 10 complete 
forward and back projections of the data, are sufficient to reach reasonable convergence
for clinical purposes when using preconditioning and proper sampling of the subsets.

Without loss of generality, we focus in this work on the time-of-flight (TOF) PET reconstruction 
using TV regularization yielding the optimization problem
%
\begin{equation}
\argmin _{x\geq 0} \sum_j \underbrace{(Px)_j -  d_j \log \left( (Px)_ j + s_j \right)}_{D_j(x)} + \beta \, \|\nabla x\|_{1,2},
\end{equation}
%
where $x$ is the PET image to be reconstructed, $P$ is the TOF forward projector including the effects
of attenuation and normalization, $d$ are the acquired prompt TOF coincidences (the emission sinogram),
and $s$ are additive contaminations including random and scattered coincidences. $\nabla$ is the gradient
operator, and $\beta$ is a scalar controlling the level of regularization.

%-----------------------------------------------------------------------------
\begin{algorithm}[t]
\begin{algorithmic}[1]
\State \textbf{Initialize} $x(=0),y(=0)$, $(S_i)_i,T,(p_i)_i$,
\State $\overline{z} = z = P^T y$
\Repeat
	\State $x = \proj_{\geq 0} (x - T \overline{z})$
	\State Select $i \in \{ 1,\ldots,m+1\} $ randomly according to $(p_i)_i$
	\State \quad $y_i^+ \gets \prox_{D_i^*}^{S_i} ( y_i + S_i  ( P_i x + s_i))$
	\State \quad $\delta z \gets P_i^T (y_i^+ - y_i)$
	\State \quad $y_i \gets y_i^+$
	\State $z \gets z + \delta z$
	\State $\overline{z} \gets  z + (\delta z/p_i)$
\Until{Stopping criterion fulfilled}
\State \Return{$x$}
%\EndFunction
\end{algorithmic}
\caption{SPDHG algorithm for PET reconstruction \cite{Ehrhardt2019}}
\label{alg:spdhg}
\end{algorithm}
%-----------------------------------------------------------------------------

In the application of Algorithm~\ref{alg:spdhg}, we follow the approach if \cite{Ehrhardt2019}
by splitting the data into n non-overlapping subsets with the corresponding 
sequence of partial PET forwad operators denoted as $(P_i)_{i=1}^n$.
To simplify notation, we set $P_{n+1} = \nabla$ and choose the probabilities $p_1=\ldots=p_n = 1/(2n)$
and $p_{n+1} = 1/2$.
For $\rho<1$ and $\gamma>0$, we define preconditioned step sizes for the partial PET operators, 
for $i=1,\ldots,n$
\[ S_i = \gamma \, \text{diag}(\frac{\rho}{P_i 1} )\qquad  T_i = \gamma^{-1} \text{diag}(\frac{\rho p_i}{P^T_i 1}) \]
and for the gradient opertator
\[ S_{n+1} = \frac{\rho}{\|\nabla\|} \qquad T_{n+1} = \frac{p_i\rho}{\|\nabla\|} \]  
As metioned in \cite{Ehrhardt2019}, if we set $T = \min_{i=1,\ldots,n+1} T_i$ pointwise,
SPDHG converges.

The proximal operator for the convex dual of $D_j$ is given by
\begin{equation}
(\prox_{D_j^*}^{S}(y))_j = \frac{1}{2} \left(y_j + 1 + \sqrt{ (y_j-1)^2 + 4 S s_j d_j} \right)
\label{eq:proxD}
\end{equation} 
and the proximal operator for the convex dual of the TV term is given by
\begin{equation}
(\prox_{D_{n+1}^*}(y) )_j = y_j /\max(\beta,|y_j|) \ .
\end{equation}

As discussed in Remark 2 of \cite{Ehrhardt2019}, a potential drawback of SPDHG is that it requires
to keep at least one more complete (TOF) sinogram (y) in memory. 
Moreover, if the proposed preconditioning is used, a second complete (TOF) sinogram
(the sequence of step sizes $(S_i)_i$) needs to be stored.
In general this is less of a problem for static single-bed non-TOF PET data where sinogram sizes, 
are relatively small.
However, for simulataneous multi-bed, dynamic or TOF PET data, the size of complete sinograms
can be become problematic, especially when using GPUs.
E.g. for modern PET TOF scanners with 25\,cm axial FOV and a TOF resolution of ca. 400\,ps, 
a complete unmashed TOF sinogram in single precision for one bed position 
has approximately $4.4\cdot10^9$ data bins requiring ca. 17\,GB of memory.
Note that the memory required to store one sinogram will increase with better TOF resolution.
Due to large number of data bins and the limitations in injected dose and acquisition time,
modern TOF sinogram are usually very sparse, meaning that many (most) data bins no data is
acquired.
E.g. for a late static 10\,min FDG brain scan with 150\,MBq injected dose in modern PET/MR 
60\,min p.i., typically $10^8$ prompt coicindences are acquired and around XXX\,\% of the
data bins are empty.
For a typical 2\,min whole-body FDG bed position, 60\,min p.i. only XXX prompt coincidences
are acquired and around XXX\,\% of the data bins are empty.

\smallskip

In this work, we propose and analyze a better initialization of SPDHG for sparse PET data
which leads to a substantially reduces the memory requirements.
Moreover, we also analyse the influence of the scalar parameter $\gamma$ that determines
the ratio between the primal an dual step sizes on the convergence of SPDHG.




%-------------------------------------------------------------------------------------------
\printbibliography

\end{document}
