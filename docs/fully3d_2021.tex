% Latex template for submission to the 16th International Meeting on Fully 3D Image Reconstruction 
% in Radiology and Nuclear Medicine (Fully3D 2021)
%
% Author: G.Schramm
% Date:   Oct 2020
%
% In case you encouter problems, you can raise a github issue here:
% https://github.com/gschramm/fully3d_2021_templates/issues
%
% 
% To build this document, we recommend to use latexmk via:
% ```latexmk -pdf fully3d_template.tex```
% Building in the online editor overleaf also works.

\documentclass[11pt,twocolumn,twoside]{article}
\usepackage{fully3d}

%%%%%% add your extra packages here (if needed)                                       %%%%%
%%%%%% before, have a look which packages are already imported by the fully3d package %%%%%

\usepackage{amssymb}
\usepackage{algorithmicx}
\usepackage{algpseudocode}

% define float env for algorithm
\usepackage{float}
\floatstyle{ruled}
\newfloat{algorithm}{h}{loa}
\floatname{algorithm}{Algorithm}

%%%%% add your bibtex file that contains the bibtex entries here %%%%%
%%%%% please include DOIs in the bibtex entries if possible      %%%%%
\addbibresource{fully3d_2021.bib}

% custom definitions
\DeclareMathOperator{\proj}{proj}
\DeclareMathOperator{\prox}{prox}
\DeclareMathOperator*{\argmin}{arg\,min}

\begin{document}


%-------------------------------------------------------------------------------------------
%%%%% add your title here %%%%%
\title{Fast and memory-efficient reconstruction of sparse TOF PET data with non-smooth priors} 

%%%%% add authors and affiliations here %%%%%
\author[1]{Georg~Schramm}
\author[2]{Martin~Holler}

\affil[1]{Department of Imaging and Pathology, Division of Nuclear Medicine,
          KU Leven, Belgium}

\affil[2]{Institute for Mathematics and Scientific Computing, 
          University of Graz, Austria}

%%%%% don't change these 2 lines %%%%%
\maketitle
\thispagestyle{fancy}



%-------------------------------------------------------------------------------------------
%%%%% add your summary (abstract) here               %%%%%%
%%%%% use footnotesize for this section              %%%%%%
%%%%% please stick to the customabstract environment %%%%%% 


\begin{customabstract}
Foo bar.
\end{customabstract}


%-------------------------------------------------------------------------------------------
%%%%% main text %%%%%    
\section{Introduction}

Due to limitations in acquisition time, injectable dose and scanner sensitivity,
acquired data in positron emission tomography (PET) suffer from high levels of
Poisson noise that is transfered into the reconstructed image necessitating
noise suppression during or post reconstruction.
One possible way of noise suppression is the maximum a posteriori approach
where a smoothing prior added next to the data fidelity term (the negative
Poisson loglikelihood) in the cost function optimized in iterative image 
reconstruction.
Unfortunately, many advanced smoothing priors such as e.g. Total Variation (TV) [XXX],
Generalized TV [XXX], Directional TV [XXX] or Parallel Level Sets [XXX] are non-smooth 
functions which permits the use of simple and efficient purely gradient-based
optimization algortihms.
Moreover, due to the large number of data bins in a (time-of-flight) sinogram
of modern PET scanners, the compution time for a single evaluation of the complete
forward (and adjoint) model is usually slow favoring optimiztion algorithms that
use only a subset of the data ine every update step like maximum expectation maximization
with ordered subsets (OSEM).

Recently, Chambolle et al. \cite{Chambolle2018} and  Ehrhardt et al. \cite{Ehrhardt2019} introduced 
the stochastic primal dual hybrid gradient (SPDHG) algorithm which is a convergent algorithms
to allows to solve the PET reconstruction problem inlcuding many non-smooth priors with
only a few iterations. 
Algorithm \ref{alg:spdhg} shows SPDHG using a typical PET forward model.
As seen in line 6 and 7, in every update only a forward and backprojection of subset
of the data is required.
Using two clinical FDG and Fluorbetapir data sets from the Siemens mMR, 
it was shown in \cite{Ehrhardt2019}, that approximately 10 iterations, meaning 10 complete 
forward and back projections of the data, are sufficient to reach reasonable convergence
for clinical purposes when using preconditioning and proper sampling of the subsets.

Without loss of generality, we focus in this work on the time-of-flight (TOF) PET reconstruction 
using TV regularization yielding the optimization problem
%
\begin{equation}
\argmin _{x\geq 0} \sum_j \underbrace{(Px)_j -  d_j \log \left( (Px)_ j + s_j \right)}_{D_j(x)} + \beta \, \|\nabla x\|_{1,2},
\end{equation}
%
where $x$ is the PET image to be reconstructed, $P$ is the TOF forward projector including the effects
of attenuation and normalization, $d$ are the acquired prompt TOF coincidences (the emission sinogram),
and $s$ are additive contaminations including random and scattered coincidences. $\nabla$ is the gradient
operator, and $\beta$ is a scalar controlling the level of regularization.

%-----------------------------------------------------------------------------
\begin{algorithm}[t]
\begin{algorithmic}[1]
\State \textbf{Initialize} $x(=0),y(=0)$, $(S_i)_i,T,(p_i)_i$,
\State $\overline{z} = z = P^T y$
\Repeat
	\State $x = \proj_{\geq 0} (x - T \overline{z})$
	\State Select $i \in \{ 1,\ldots,m+1\} $ randomly according to $(p_i)_i$
	\State \quad $y_i^+ \gets \prox_{D_i^*}^{S_i} ( y_i + S_i  ( P_i x + s_i))$
	\State \quad $\delta z \gets P_i^T (y_i^+ - y_i)$
	\State \quad $y_i \gets y_i^+$
	\State $z \gets z + \delta z$
	\State $\overline{z} \gets  z + (\delta z/p_i)$
\Until{stopping criterion fulfilled}
\State \Return{$x$}
%\EndFunction
\end{algorithmic}
\caption{SPDHG algorithm for PET reconstruction \cite{Ehrhardt2019}}
\label{alg:spdhg}
\end{algorithm}
%-----------------------------------------------------------------------------

In the application of Algorithm~\ref{alg:spdhg}, we follow the approach if \cite{Ehrhardt2019}
by splitting the data into n non-overlapping subsets with the corresponding 
sequence of partial PET forwad operators denoted as $(P_i)_{i=1}^n$.
To simplify notation, we set $P_{n+1} = \nabla$ and choose the probabilities $p_1=\ldots=p_n = 1/(2n)$
and $p_{n+1} = 1/2$.
For $\rho<1$ and $\gamma>0$, we define preconditioned step sizes for the partial PET operators, 
for $i=1,\ldots,n$
\[ S_i = \gamma \, \text{diag}(\frac{\rho}{P_i 1} )\qquad  T_i = \gamma^{-1} \text{diag}(\frac{\rho p_i}{P^T_i 1}) \]
and for the gradient opertator
\[ S_{n+1} = \frac{\rho}{\|\nabla\|} \qquad T_{n+1} = \frac{p_i\rho}{\|\nabla\|} \]  
As metioned in \cite{Ehrhardt2019}, if we set $T = \min_{i=1,\ldots,n+1} T_i$ pointwise,
SPDHG converges.

The proximal operator for the convex dual of $D_j$ is given by
\begin{equation}
(\prox_{D_j^*}^{S}(y))_j = \frac{1}{2} \left(y_j + 1 + \sqrt{ (y_j-1)^2 + 4 S s_j d_j} \right)
\label{eq:proxD}
\end{equation} 
and the proximal operator for the convex dual of the TV term is given by
\begin{equation}
(\prox_{D_{n+1}^*}(y) )_j = y_j /\max(\beta,|y_j|) \ .
\end{equation}

As discussed in Remark 2 of \cite{Ehrhardt2019}, a potential drawback of SPDHG is that it requires
to keep at least one more complete (TOF) sinogram (y) in memory. 
Moreover, if the proposed preconditioning is used, a second complete (TOF) sinogram
(the sequence of step sizes $(S_i)_i$) needs to be stored.
In general this is less of a problem for static single-bed non-TOF PET data where sinogram sizes, 
are relatively small.
However, for simulataneous multi-bed, dynamic or TOF PET data, the size of complete sinograms
can be become problematic, especially when using GPUs.
E.g. for modern PET TOF scanners with 25\,cm axial FOV and a TOF resolution of ca. 400\,ps, 
a complete unmashed TOF sinogram in single precision for one bed position 
has approximately $4.4\cdot10^9$ data bins requiring ca. 17\,GB of memory.
Note that the memory required to store a complete TOF sinogram will further 
increase with better TOF resolution.
Due to large number of data bins and the limitations in injected dose and acquisition time,
modern TOF sinograms are usually very sparse, meaning that most data bins no data is
acquired.
E.g. for a typical 3\,min-per-bed-position whole-body FDG scan with an injected dose 
of around 200\,MBq acquired 60\,min p.i. on a state-of-the-art TOF PET/MR scanner, 
more than 95\% of the data (TOF sinogram) bins are empty.
For short early frames in dynamic brain scans, this fraction is even higher.
And even for ``high count'' late static 20\,min FDG brain scans with an injected dose of 150\,MBq
acquired 60\,min p.i., still around 70\% of the data bins are empty.

\smallskip

Considering the very sprase nature of TOF emission sinograms,
in this work, we propose and analyze a better initialization of SPDHG for sparse PET data
which substantially reduces the memory requirements.
Moreover, we also analyse the influence of the scalar hyper parameter $\gamma$, that determines
the ratio between the primal an dual step sizes, on the convergence of SPDHG.



%-----------------------
%-----------------------
%-----------------------


\section{Materials and Methods}

\subsection{Memory efficient TOF PET SPDHG through better initialization}

In~\cite{Ehrhardt2019}, the authors propose to initialize $x$ and $y$ with zeros everywhere.
However, we can observe from Eq.~(\ref{eq:proxD}) that for data bins $j$ where $d_j = 0$ 
(empty TOF sinogram bins), 
$(\prox_{D_j^*}(a))_j = 1$ for $a_j \geq 1$ and $(\prox_{D_i^*}(a))_j = a_j$ otherwise. 
Moreover, we see that $ a_j = (y_i + S_i (P_i x + s_i) )_j \geq 1$ provided that $(y_i)_j \geq 1$ 
since all other quantities are positive. 
Hence, if we initialize all bins of $y$ where the data $d$ equals zero with $1$, 
these bins remain equal to $1$ during all iterations. 
This in turn means that these bins do not contribute to the solution, since only the change
in $y$ is backprojected in line 7 of algorithm~\ref{alg:spdhg}.
Consequently, this implies that these bins do not need to be kept in memory after the initialization
of the $z$ and $\bar{z}$ with the backprojection of $y$ which dramatically reduces the memory
requirement and also the number of projections that need to be calculated keeping in mind that
for most acquisitions with modern TOF PET scanners most of the data bins are 0 as discussed before.
To differentiate between SPDHG with the originally proposed intilization and the initialization proposed
above, we call the latter SPDHG-S.

\subsection{Numerical experiments}

To compare the convergence of SPDHG and SPDHG-S, we performed reconstructions of simulated
TOF PET data from a virtual 2D scanner mimicking the TOF resolution (ca. 400\,ps FWHM) and 
geometry of one ring (direct plane) of the GE SIGNA PET/MR (sinogram dimension: 
357 radial bins, 224 projection angles, 27 TOF bins).
A software brain phantom with a typical grey to white matter contrast of 4:1 was created
based on the brainweb phantom and used to generate simulated data including the effects
of attenuation and flat contamination (scattered) coincidences
with a simulated scatter fraction of 16\%.
Noisy simualted prompt emission TOF sinograms where generated for $10^5$, $10^6$, 
and $10^7$ counts. %%%XXX mention sparsity of sinograms
The simulated data were reconstructed with SPDHG and SPDHG-S using 50 iterations, 112 subsets,
a fixed level regularization ($\beta = 0.6$ for $10^5$ counts, and $\beta = 0.2$ for $10^6$
and $10^7$ counts), and different values for $\gamma$.
As in \cite{Ehrhardt2019}, convergence was monitored by tracking the relative cost function
\[ c_\text{rel} = (c(x) - c(x^*)) / (c(x^0) - c(x^*)). \]
and the peak signal to noise ratio 
\[ \text{PSNR} = 20 \log_{10} (\|x^*\|_\infty/\sqrt{\text{MSE}(x,x^*)}) \]
compared to an approximate minimizer $x^*$.
which was calculated using the deterministic PDHG with 5000 iterations without subsets.
In all reconstructions, the TOF PET operator $P$ was renormalized such that the norm of $P$
equaled the number of projection angles.
Subsets were defined via equidistant projection angles.


%-------------------------------------------------------------------------------------------
\printbibliography

\end{document}
